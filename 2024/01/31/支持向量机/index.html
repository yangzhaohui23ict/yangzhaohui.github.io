<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>支持向量机 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="支持向量机间隔与支持向量​	对于一组线性可分的数据，分类学习最基本的想法就是基于训练集，在样本空间中找到一个划分超平面，但是同样是可以实现划分，超平面之间亦有差距。那么我们真正要的是哪一个呢？ ​	以朴素的直接思维来看，肯定就是两类样本最中间的划分平面，这样做泛化性能和对于扰动的容忍性最好。 ​	基于我们这样的思路，我们需要计算的第一个数据就是样本点到这个超平面的距离，这里我们描述超平面为：wTx">
<meta property="og:type" content="article">
<meta property="og:title" content="支持向量机">
<meta property="og:url" content="http://example.com/2024/01/31/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="支持向量机间隔与支持向量​	对于一组线性可分的数据，分类学习最基本的想法就是基于训练集，在样本空间中找到一个划分超平面，但是同样是可以实现划分，超平面之间亦有差距。那么我们真正要的是哪一个呢？ ​	以朴素的直接思维来看，肯定就是两类样本最中间的划分平面，这样做泛化性能和对于扰动的容忍性最好。 ​	基于我们这样的思路，我们需要计算的第一个数据就是样本点到这个超平面的距离，这里我们描述超平面为：wTx">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/pic/image-20240112100937612.png">
<meta property="og:image" content="http://example.com/pic/image-20240112102208826.png">
<meta property="og:image" content="http://example.com/pic/image-20240112102349115.png">
<meta property="og:image" content="http://example.com/pic/image-20240112102436186.png">
<meta property="og:image" content="http://example.com/pic/image-20240112102441837.png">
<meta property="og:image" content="http://example.com/pic/image-20240112104621941.png">
<meta property="og:image" content="http://example.com/pic/image-20240112104700413.png">
<meta property="og:image" content="http://example.com/pic/image-20240112104959940.png">
<meta property="og:image" content="http://example.com/pic/image-20240112105011736.png">
<meta property="og:image" content="http://example.com/pic/image-20240112105518155.png">
<meta property="og:image" content="http://example.com/pic/image-20240112111645622.png">
<meta property="og:image" content="http://example.com/pic/image-20240112111933635.png">
<meta property="og:image" content="http://example.com/pic/image-20240112112812779.png">
<meta property="og:image" content="http://example.com/pic/image-20240112114910656.png">
<meta property="og:image" content="http://example.com/pic/image-20240112164647635.png">
<meta property="og:image" content="http://example.com/pic/image-20240112164731935.png">
<meta property="og:image" content="http://example.com/pic/image-20240112165517109.png">
<meta property="og:image" content="http://example.com/pic/image-20240112170458666.png">
<meta property="og:image" content="http://example.com/pic/image-20240112171538291.png">
<meta property="og:image" content="http://example.com/pic/image-20240112172205244.png">
<meta property="og:image" content="http://example.com/pic/image-20240112230115724.png">
<meta property="og:image" content="http://example.com/pic/image-20240112230508477.png">
<meta property="og:image" content="http://example.com/pic/image-20240112230526036.png">
<meta property="og:image" content="http://example.com/pic/image-20240112232443697.png">
<meta property="og:image" content="http://example.com/pic/image-20240112232448659.png">
<meta property="og:image" content="http://example.com/pic/image-20240112232454891.png">
<meta property="article:published_time" content="2024-01-31T06:20:01.000Z">
<meta property="article:modified_time" content="2024-01-31T06:20:28.002Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="国科大模式识别与机器学习23秋季学习笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/pic/image-20240112100937612.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-支持向量机" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/01/31/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" class="article-date">
  <time class="dt-published" datetime="2024-01-31T06:20:01.000Z" itemprop="datePublished">2024-01-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">课程学习笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      支持向量机
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h2 id="间隔与支持向量"><a href="#间隔与支持向量" class="headerlink" title="间隔与支持向量"></a>间隔与支持向量</h2><p>​	对于一组线性可分的数据，分类学习最基本的想法就是基于训练集，在样本空间中找到一个划分超平面，但是同样是可以实现划分，超平面之间亦有差距。那么我们真正要的是哪一个呢？</p>
<p>​	以朴素的直接思维来看，肯定就是两类样本最中间的划分平面，这样做泛化性能和对于扰动的容忍性最好。</p>
<p>​	基于我们这样的思路，我们需要计算的第一个数据就是样本点到这个超平面的距离，这里我们描述超平面为：w<sup>T</sup>x+b&#x3D;0，则对于样本点x，到超平面的距离为：</p>
<p><img src="/./../pic/image-20240112100937612.png" alt="image-20240112100937612"></p>
<p>​	如果对于一个线性可分的数据，可以正确分类，这说明对于一个样本有：</p>
<p><img src="/./../pic/image-20240112102208826.png" alt="image-20240112102208826"></p>
<p>​	这个地方之所以有等号，是因为这个等式的划分需要考虑距离这个超平面最近的几个样本点，也就是“支持向量”，两个异类支持向量到超平面的距离被称为<strong>间隔</strong>。</p>
<p>​	<img src="/./../pic/image-20240112102349115.png" alt="image-20240112102349115"></p>
<p>​	基于此，我们就可以确定我们这个工作的主要目标函数：令间隔尽可能大同时实现对于数据的划分。</p>
<p><img src="/./../pic/image-20240112102436186.png" alt="image-20240112102436186"></p>
<p>​	这两个是相同概念：</p>
<p><img src="/./../pic/image-20240112102441837.png" alt="image-20240112102441837"></p>
<h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><p>​	对于上面的目标函数，也就是有约束的最值问题，可以使用拉格朗日乘子法进行求解，上式可以写作：</p>
<p><img src="/./../pic/image-20240112104621941.png" alt="image-20240112104621941"></p>
<p>​	不过这里需要明确α<sub>i</sub>&gt;&#x3D;0。</p>
<p>​	对于上式w,b求导可得：</p>
<p><img src="/./../pic/image-20240112104700413.png" alt="image-20240112104700413"></p>
<p>​	基于求导结果，带入回去拉格朗日乘子式，可以消去w,b，成为一个对于α的最值问题，也可以说是这个公式的对偶问题：</p>
<p><img src="/./../pic/image-20240112104959940.png" alt="image-20240112104959940"></p>
<p><img src="/./../pic/image-20240112105011736.png" alt="image-20240112105011736"></p>
<p>​	基于此计算得到α之后，回过头去就可以求解w,b进而得到整体模型。因为存在不等式约束，上述过程满足KKT条件，即：</p>
<p><img src="/./../pic/image-20240112105518155.png" alt="image-20240112105518155"></p>
<p>​	这个条件的含义就是，除非是最大间隔边界上的支持向量，其他样例的α&#x3D;0，若α不等于0，则一定满足yf(x)&#x3D;1，是一个支持向量。</p>
<p>​	所以现在的关键就是对上面提到的对偶问题的求解。这个地方是一个二次规划问题，常用的算法就是SMO。</p>
<p>​	这个地方还有一个计算方法就是：</p>
<p><img src="/./../pic/image-20240112111645622.png" alt="image-20240112111645622"></p>
<p>​	就这个方法，求得α进而W可计算，同时支持向量可确定，因此，带一个支持向量，可计算得到b</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>​	我们前面这些内容的前提假设就是样本线性可分。但是有时候这个情况是不满足的，此时就需要我们对于数据进行升维，然后尝试在更高维的层面上，完成线性分类：</p>
<p><img src="/./../pic/image-20240112111933635.png" alt="image-20240112111933635"></p>
<p>​	只要原始空间维度有限，一定存在一个高位特征空间使得样本可分。∅(x)表示为样本点映射之后的特征向量。然后问题就回到了上面提到的部分，只要替换x就行。</p>
<p><img src="/./../pic/image-20240112112812779.png" alt="image-20240112112812779"></p>
<p>​	但是这个地方存在一个小bug就是∅(x<sub>i</sub>)<sup>T</sup>∅(x<sub>j</sub>)因为升维的原因，维度很高甚至是无限维度。因此直接计算并不容易，所以核函数出了一个小tips：</p>
<p><img src="/./../pic/image-20240112114910656.png" alt="image-20240112114910656"></p>
<p>​	也就是直接在原始空间样本，通过k直接计算结果。基于k我们就不用去计算过高维度的空间内积，省下来很大的计算量：</p>
<p><img src="/./../pic/image-20240112164647635.png" alt="image-20240112164647635"></p>
<p>​	求解后可得：</p>
<p><img src="/./../pic/image-20240112164731935.png" alt="image-20240112164731935"></p>
<p>​	对于核函数和k，我们可以理解为一个正定矩阵，我们不需要知道核函数向高维的映射方式，但是需要知道任意两个元素映射之后高维状态内积的结果：</p>
<p><img src="/./../pic/image-20240112165517109.png" alt="image-20240112165517109"></p>
<h2 id="软间隔与正则化"><a href="#软间隔与正则化" class="headerlink" title="软间隔与正则化"></a>软间隔与正则化</h2><p>​	核函数是一种很好的针对于数据不线性可分的情况的方法，但是我们需要知道的一点就是有些时候核函数的处理方式就好比是高烧打米塞地松，是有一定隐患的。</p>
<p>​	缓解该问题的办法是允许模型在一些样本上出错，为此引入了软间隔的概念。</p>
<p><img src="/./../pic/image-20240112170458666.png" alt="image-20240112170458666"></p>
<p>​	在我们前面提到的约束条件下，所有样本都必须划分正确，这成为硬间隔。而软间隔则允许有一些样本不满足定好的约束。</p>
<p>​	但是我们不能无限制的纵容他们，我们希望的是在间隔最大化的同时，尽可能减少不满足约束的样本个数。</p>
<p>​	因此，目标函数可以表示为：</p>
<p><img src="/./../pic/image-20240112171538291.png" alt="image-20240112171538291"></p>
<p>​	前面的部分就是正常间隔大小，后半部分则是对于那些不满足约束的样本，造成的损失部分，其中l<sub>0&#x2F;1</sub>是一个0-1判别，无关于脱离约束的程度，只要脱离了就是1。C是软间隔下的超参数，C无限大的时候，将迫使所有样本满足约束，C越小，对于样本跳脱的容忍度越高。</p>
<p>​	对于l<sub>0&#x2F;1</sub>还有其他函数替换，类似hinge损失（也叫合页损失），指数损失，优点在于连续，并且和样本脱离的程度有关。</p>
<p>​	一些损失函数：<img src="/./../pic/image-20240112172205244.png" alt="image-20240112172205244"></p>
<p>​	</p>
<h2 id="支持向量回归"><a href="#支持向量回归" class="headerlink" title="支持向量回归"></a>支持向量回归</h2><p>​	这个地方重点在于回归，传统回归模型是基于模型输出和真实的输出之间的不同来计算损失。</p>
<p>​	支持向量回归这里，我们使用了之前提到的间隔概念，我们认为只要偏差可控，在一定范围内，就可以被认为是预测正确的。</p>
<p>​	下图中阴影部分就是认为正确预测的样例。</p>
<p><img src="/./../pic/image-20240112230115724.png" alt="image-20240112230115724"></p>
<p>​	这样的情况下，问题的损失函数为：</p>
<p><img src="/./../pic/image-20240112230508477.png" alt="image-20240112230508477"></p>
<p>​	其中L为：<img src="/./../pic/image-20240112230526036.png" alt="image-20240112230526036"></p>
<p>​	<img src="/./../pic/image-20240112232443697.png" alt="image-20240112232443697"></p>
<p><img src="/./../pic/image-20240112232448659.png" alt="image-20240112232448659"></p>
<p><img src="/./../pic/image-20240112232454891.png" alt="image-20240112232454891"></p>
<p>​	转到对偶问题之后就没什么不同的了。</p>
<h1 id="考试考点"><a href="#考试考点" class="headerlink" title="考试考点"></a>考试考点</h1><p>​	SVM硬间隔对偶问题的计算。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/01/31/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" data-id="cls1ef0lm0000z8uebxlkg16c" data-title="支持向量机" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BD%E7%A7%91%E5%A4%A7%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A023%E7%A7%8B%E5%AD%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">国科大模式识别与机器学习23秋季学习笔记</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/01/31/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          集成学习
        
      </div>
    </a>
  
  
    <a href="/2024/01/31/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">半监督学习</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">课程学习笔记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BD%E7%A7%91%E5%A4%A7%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A023%E7%A7%8B%E5%AD%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">国科大模式识别与机器学习23秋季学习笔记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/%E5%9B%BD%E7%A7%91%E5%A4%A7%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A023%E7%A7%8B%E5%AD%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">国科大模式识别与机器学习23秋季学习笔记</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/01/31/%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/">降维与度量学习</a>
          </li>
        
          <li>
            <a href="/2024/01/31/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">集成学习</a>
          </li>
        
          <li>
            <a href="/2024/01/31/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">支持向量机</a>
          </li>
        
          <li>
            <a href="/2024/01/31/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">半监督学习</a>
          </li>
        
          <li>
            <a href="/2024/01/30/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/">贝叶斯分类器</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>